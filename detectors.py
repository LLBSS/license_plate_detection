import cv2
import numpy as np
import os
import json
from datetime import datetime
import image_utils
import color_detector
import argparse


class LicensePlateDetector:
    def __init__(self, low_threshold=50, high_threshold=150, blur_size=5):
        self.low_threshold = low_threshold
        self.high_threshold = high_threshold
        self.blur_size = blur_size
    
    def preprocess_image(self, image):
        """å›¾åƒé¢„å¤„ç†ï¼šç°åº¦åŒ– + é«˜æ–¯æ¨¡ç³Š"""
        if len(image.shape) == 3:
            gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        else:
            gray_image = image.copy()
        
        # é«˜æ–¯æ¨¡ç³Šé™å™ª
        blurred_image = cv2.GaussianBlur(gray_image, (self.blur_size, self.blur_size), 0)
        return gray_image, blurred_image
    
    def canny_edge_detection(self, image):
        """Cannyè¾¹ç¼˜æ£€æµ‹"""
        gray_image, blurred_image = self.preprocess_image(image)
        edges = cv2.Canny(blurred_image, self.low_threshold, self.high_threshold, apertureSize=3)
        return gray_image, blurred_image, edges
    
    def morphological_operations(self, edges):
        """
        æ‰§è¡Œå¼€è¿ç®—å’Œé—­è¿ç®—çš„å½¢æ€å­¦æ“ä½œ
        å¼€è¿ç®—ï¼šå…ˆè…èš€åè†¨èƒ€ï¼Œç”¨äºå»é™¤å™ªå£°ã€å­¤ç«‹ç‚¹
        é—­è¿ç®—ï¼šå…ˆè†¨èƒ€åè…èš€ï¼Œç”¨äºè¿æ¥å°çš„é—´éš™
        """
        # å¼€è¿ç®—ï¼šå»é™¤å°å™ªå£°ï¼Œä¿ç•™å¤§çš„è¾¹ç¼˜ç»“æ„
        open_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))
        opened_edges = cv2.morphologyEx(edges, cv2.MORPH_OPEN, open_kernel)
        
        # é—­è¿ç®—ï¼šè¿æ¥è½¦ç‰Œå­—ç¬¦ä¹‹é—´çš„é—´éš™ï¼Œå¼ºåŒ–è½¦ç‰ŒåŒºåŸŸ
        # ä½¿ç”¨æ°´å¹³æ–¹å‘çš„é•¿æ–¹å½¢æ ¸ï¼Œæ›´å¥½åœ°è¿æ¥è½¦ç‰Œå­—ç¬¦
        
        close_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (15, 3))
        closed_edges = cv2.morphologyEx(opened_edges, cv2.MORPH_CLOSE, close_kernel)
        
        return opened_edges, closed_edges
    
    def detect_vertical_edges(self, gray_image):
        """ä½¿ç”¨Sobelç®—å­æ£€æµ‹å‚ç›´è¾¹ç¼˜ï¼Œè½¦ç‰Œå­—ç¬¦ä¸»è¦åŒ…å«å‚ç›´è¾¹ç¼˜"""
        # Sobelå‚ç›´æ–¹å‘ç®—å­
        sobel_y = cv2.Sobel(gray_image, cv2.CV_64F, 0, 1, ksize=3)
        
        # å–ç»å¯¹å€¼å¹¶è½¬æ¢ä¸º8ä½
        vertical_edges = np.absolute(sobel_y)
        vertical_edges = np.uint8(255 * vertical_edges / np.max(vertical_edges))
        
        return vertical_edges
    
    def enhance_license_plate_features(self, vertical_edges):
        """å¢å¼ºè½¦ç‰Œç‰¹å¾ï¼šå¼ºåŒ–å‚ç›´è¾¹ç¼˜ï¼Œé€‚åˆè½¦ç‰Œå®½é«˜æ¯”"""
        # äºŒå€¼åŒ–çªå‡ºå¼ºå‚ç›´è¾¹ç¼˜
        _, vertical_binary = cv2.threshold(vertical_edges, 80, 255, cv2.THRESH_BINARY)
        
        # å½¢æ€å­¦æ“ä½œå¢å¼ºå‚ç›´çº¿æ¡ï¼ˆé€‚åˆè½¦ç‰Œå­—ç¬¦ï¼‰
        # å‚ç›´æ–¹å‘çš„å°å†…æ ¸ï¼Œå¼ºåŒ–å­—ç¬¦å‚ç›´è¾¹ç¼˜
        vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 3))
        enhanced_vertical = cv2.morphologyEx(vertical_binary, cv2.MORPH_DILATE, vertical_kernel)
        
        # ä½¿ç”¨é€‚åˆè½¦ç‰Œå½¢çŠ¶çš„é—­è¿ç®—æ ¸ï¼ˆé•¿çŸ©å½¢ï¼‰
        license_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (20, 5))
        enhanced_vertical = cv2.morphologyEx(enhanced_vertical, cv2.MORPH_CLOSE, license_kernel)
        
        return enhanced_vertical
    
    def find_contours(self, processed_image):
        """å¯»æ‰¾å›¾åƒä¸­çš„è½®å»“"""
        # å¯»æ‰¾æ‰€æœ‰è½®å»“
        contours, _ = cv2.findContours(processed_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        return contours
    
    def filter_license_plate_contours(self, contours, min_area=2000, max_area=50000):
        """
        æ ¹æ®è½¦ç‰Œç‰¹å¾è¿‡æ»¤è½®å»“
        è½¦ç‰Œç‰¹å¾ï¼šçŸ©å½¢å½¢çŠ¶ã€ç‰¹å®šçš„å®½é«˜æ¯”ï¼ˆé€šå¸¸åœ¨2.5:1åˆ°4:1ä¹‹é—´ï¼‰
        """
        license_plates = []
        
        for contour in contours:
            # è®¡ç®—è½®å»“é¢ç§¯
            area = cv2.contourArea(contour)
            
            # é¢ç§¯è¿‡æ»¤
            if area < min_area or area > max_area:
                continue
            
            # è·å–æœ€å°å¤–æ¥çŸ©å½¢
            x, y, w, h = cv2.boundingRect(contour)
            
            # è®¡ç®—å®½é«˜æ¯”
            if h == 0:
                continue
            aspect_ratio = w / h
            
            # è½¦ç‰Œå®½é«˜æ¯”é€šå¸¸åœ¨2.5:1åˆ°4:1ä¹‹é—´
            # ä¸­å›½è½¦ç‰Œæ¯”ä¾‹çº¦ä¸º2.89:1 (440mmÃ—140mm)
            if 2.0 < aspect_ratio < 5.0:
                # è®¡ç®—è½®å»“çš„çŸ©å½¢åº¦ï¼ˆé¢ç§¯ä¸æœ€å°å¤–æ¥çŸ©å½¢é¢ç§¯çš„æ¯”å€¼ï¼‰
                rect_area = w * h
                rect_ratio = area / rect_area if rect_area > 0 else 0
                
                # è½¦ç‰Œåº”è¯¥æ¥è¿‘çŸ©å½¢
                if rect_ratio > 0.5:
                    license_plates.append({
                        'x': x,
                        'y': y,
                        'width': w,
                        'height': h,
                        'area': area,
                        'aspect_ratio': aspect_ratio,
                        'rect_ratio': rect_ratio,
                        'confidence': rect_ratio * (1 - abs(aspect_ratio - 3.0) / 3.0)  # åŸºäºçŸ©å½¢åº¦å’Œå®½é«˜æ¯”çš„ç½®ä¿¡åº¦
                    })
        
        # æŒ‰ç½®ä¿¡åº¦æ’åº
        license_plates.sort(key=lambda lp: lp['confidence'], reverse=True)
        return license_plates
    
    def detect_license_plates(self, image):
        #print("=== æ ‡è®°ç‚¹1: å¼€å§‹è½¦ç‰Œæ£€æµ‹ ===")
        """å®Œæ•´çš„è½¦ç‰Œæ£€æµ‹æµç¨‹"""
        # 1. Cannyè¾¹ç¼˜æ£€æµ‹
        gray_image, blurred_image, canny_edges = self.canny_edge_detection(image)
        # Step 2: è½¦ç‰Œé¢œè‰²æ£€æµ‹
        detector = color_detector.WhitePlateDetector()
        mask_image = detector.detect_plates_by_white_colors(image)
        white_mask = mask_image['white']
        
        # 2. å½¢æ€å­¦æ“ä½œï¼šå¼€è¿ç®—å’Œé—­è¿ç®—
        opened_edges, closed_edges = self.morphological_operations(white_mask)
        
        # 3. å‚ç›´è¾¹ç¼˜æ£€æµ‹å’Œå¢å¼º
        vertical_edges = self.detect_vertical_edges(gray_image)
        enhanced_vertical = self.enhance_license_plate_features(vertical_edges)
        
        # 4. ç»“åˆé—­è¿ç®—ç»“æœå’Œå¢å¼ºçš„å‚ç›´è¾¹ç¼˜
        #combined_result = cv2.bitwise_and(closed_edges, enhanced_vertical)
        combined_result = cv2.bitwise_and(opened_edges, enhanced_vertical)

        # 5. å¯»æ‰¾è½®å»“
        contours = self.find_contours(combined_result)
        first_contour = np.array(contours[0])
        # 6. è¿‡æ»¤å‡ºå¯èƒ½çš„è½¦ç‰ŒåŒºåŸŸ
        #license_plates = self.filter_license_plate_contours(contours)
        license_plates = self.filter_license_plate_contours(first_contour)
        license_plates = np.array(license_plates)
        # 7. äºŒæ¬¡å¼€è¿ç®—å’Œé—­è¿ç®—
        close_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (15, 5))
        second_closed_edge = cv2.morphologyEx(combined_result, cv2.MORPH_CLOSE, close_kernel)

        return {
            'gray_image': gray_image,
            'white_mask': white_mask,
            'canny_edges': canny_edges,
            'opened_edges': opened_edges,
            'closed_edges': closed_edges,
            'vertical_edges': vertical_edges,
            'enhanced_vertical': enhanced_vertical,
            'combined_result': combined_result,
            'contours': first_contour,
            'license_plates': license_plates,
            'second_closed_edge': second_closed_edge
        }
    
    def draw_license_plates(self, image, results):
        """åœ¨å›¾åƒä¸Šç»˜åˆ¶æ£€æµ‹åˆ°çš„è½¦ç‰ŒåŒºåŸŸ"""
        result_image = image.copy()
        
        # ç»˜åˆ¶æ£€æµ‹åˆ°çš„è½¦ç‰Œï¼ˆç»¿è‰²çŸ©å½¢æ¡†ï¼‰
        for i, plate in enumerate(results['license_plates']):
            x, y, w, h = plate['x'], plate['y'], plate['width'], plate['height']
            cv2.rectangle(result_image, (x, y), (x + w, y + h), (0, 255, 0), 3)
            
            # æ·»åŠ æ ‡ç­¾
            label = f"Plate {i+1} (AR:{plate['aspect_ratio']:.2f}, Conf:{plate['confidence']:.2f})"
            cv2.putText(result_image, label, (x, y-10), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
        
        return result_image
    
    def save_detection_results(self, image, results, image_path, output_dir="result"):
        """
        ä¿å­˜æ£€æµ‹ç»“æœï¼š
        1. å°†æ ‡è®°è½¦ç‰Œçš„å›¾ç‰‡ä¿å­˜åˆ°resultæ–‡ä»¶å¤¹
        2. å°†è½¦ç‰Œåæ ‡ä¿¡æ¯ä¿å­˜ä¸ºjsonæ–‡ä»¶
        """
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)
        
        # ç”Ÿæˆæ—¶é—´æˆ³ä½œä¸ºæ–‡ä»¶åçš„ä¸€éƒ¨åˆ†
        timestamp = datetime.now().strftime("%m%d_%M%S")
        image_name = os.path.basename(image_path).split('.')[0]
        
        # ç»˜åˆ¶ç»“æœå¹¶ä¿å­˜å›¾ç‰‡
        result_image = self.draw_license_plates(image, results)
        output_image_path = os.path.join(output_dir, f"{image_name}_{timestamp}.jpg")
        cv2.imwrite(output_image_path, result_image)
        
        # å‡†å¤‡JSONæ•°æ®
        json_data = {
            "image_path": image_path,
            "timestamp": timestamp,
            "image_size": {
                "width": image.shape[1],
                "height": image.shape[0]
            },
            "license_plates": []
        }
        
        # æ·»åŠ æ¯ä¸ªè½¦ç‰Œçš„ä¿¡æ¯
        for i, plate in enumerate(results['license_plates']):
            json_data["license_plates"].append({
                "id": i + 1,
                "position": {
                    "x": plate['x'],
                    "y": plate['y'],
                    "width": plate['width'],
                    "height": plate['height']
                },
                "coordinates": [
                    [plate['x'], plate['y']],                   # å·¦ä¸Š
                    [plate['x'] + plate['width'], plate['y']],  # å³ä¸Š
                    [plate['x'] + plate['width'], plate['y'] + plate['height']],  # å³ä¸‹
                    [plate['x'], plate['y'] + plate['height']]                    # å·¦ä¸‹
                ],
                "aspect_ratio": plate['aspect_ratio'],
                "confidence": plate['confidence']
            })
        
        # ä¿å­˜JSONæ–‡ä»¶
        output_json_path = os.path.join(output_dir, f"{image_name}_{timestamp}.json")
        with open(output_json_path, 'w', encoding='utf-8') as json_file:
            json.dump(json_data, json_file, ensure_ascii=False, indent=2)
        
        return {
            "output_image": output_image_path,
            "output_json": output_json_path,
            "license_plates_count": len(results['license_plates'])
        }

def main():
    parser = argparse.ArgumentParser(description='è½¦ç‰Œå®šä½æ£€æµ‹ç³»ç»Ÿ')
    parser.add_argument('--image_path', default='examples/car3.jpg', help='è¾“å…¥å›¾åƒè·¯å¾„')
    parser.add_argument('--low-threshold', type=int, default=50, help='Cannyä½é˜ˆå€¼')
    parser.add_argument('--high-threshold', type=int, default=150, help='Cannyé«˜é˜ˆå€¼')
    parser.add_argument('--blur-size', type=int, default=5, help='é«˜æ–¯æ¨¡ç³Šå†…æ ¸å¤§å°')
    parser.add_argument('--simple', action='store_true', help='ç®€åŒ–æ¨¡å¼ï¼šåªæ˜¾ç¤ºæœ€ç»ˆç»“æœï¼Œä¸ä½¿ç”¨ç½‘æ ¼æ˜¾ç¤º')
    parser.add_argument('--no-display', action='store_true', help='ä¸æ˜¾ç¤ºä»»ä½•çª—å£')
    parser.add_argument('--no-save', action='store_true', help='ä¸ä¿å­˜ç»“æœæ–‡ä»¶')
    
    args = parser.parse_args()
    
    try:
        # åŠ è½½å›¾åƒ
        image = cv2.imread(args.image_path)
        if image is None:
            raise ValueError(f"æ— æ³•è¯»å–å›¾åƒæ–‡ä»¶: {args.image_path}")
        
        print(f"âœ… å›¾åƒåŠ è½½æˆåŠŸ: {args.image_path}")
        print(f"ğŸ“ å›¾åƒå°ºå¯¸: {image.shape[1]}x{image.shape[0]}")
        
        # åˆ›å»ºè½¦ç‰Œæ£€æµ‹å™¨
        detector = LicensePlateDetector(
            low_threshold=args.low_threshold,
            high_threshold=args.high_threshold,
            blur_size=args.blur_size
        )
        print("=== æ ‡è®°ç‚¹3: å›¾åƒæ˜¾ç¤º===")
        # æ‰§è¡Œæ£€æµ‹
        print("ğŸ” æ­£åœ¨æ£€æµ‹è½¦ç‰Œ...")
        results = detector.detect_license_plates(image)
        # æ˜¾ç¤ºæ‰€æœ‰å¤„ç†æ­¥éª¤
        image_utils.show_images(results, "è½¦ç‰Œæ£€æµ‹å…¨è¿‡ç¨‹")
        image_utils.show_images(results['white_mask'], "è½¦ç‰Œæ£€æµ‹ç»“æœ")

        # ä¿å­˜ç»“æœ
        # if not args.no_save:
        #     save_results = detector.save_detection_results(image, results, args.image_path)
        #     print(f"ğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {save_results['output_image']}")
        #     print(f"ğŸ’¾ åæ ‡æ•°æ®å·²ä¿å­˜åˆ°: {save_results['output_json']}")
        
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()